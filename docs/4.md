# Data Wrangling

<iframe width="616" height="347" src="https://www.youtube.com/embed/sz_dsktIjt4" title="Lecture 4: Data Wrangling (2020)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

你是否曾经想要将某种格式的数据转换成另一种格式 ？你肯定想过 ！

因此，本节讲座，我们将向你展示如何进行数据处理

更具体地说：无论原始数据 in text or binary format，我们都将对其进行处理，直到数据的格式符合你的需求 !

---

在前几节讲座中，其实我们已经见过一些基础的数据处理方法了

只要你使用 the `|` operator，其实你就是在进行某种形式的数据处理

比如，如果你在 shell 中执行命令 `journalctl | grep -i intel`

这条命令就会找出所有包含 intel（不区分大小写）字样的系统日志条目

You may not think of it as wrangling data, but it is going from one format (your entire system log) to a format that is more useful to you (just the intel log entries)

其实，Most data wrangling is about knowing what tools you have at your disposal, and how to combine them.

---

Let’s start from the beginning.

To wrangle data, we need two things: data to wrangle, and something to do with it.

Logs often make for a good use-case, because you often want to investigate things about them, and reading the whole thing isn’t feasible.

Let’s figure out who’s trying to log into my server by looking at my server’s log:

```bash
ssh myserver journalctl
```

That’s far too much stuff. Let’s limit it to ssh stuff:

```bash
ssh myserver journalctl | grep sshd
```

Notice that we’re using a pipe to stream a remote file through `grep` on our local computer!

`ssh` is magical, and we will talk more about it in the next lecture on the command-line environment

This is still way more stuff than we wanted though. And pretty hard to read. Let’s do better:

```bash
ssh myserver 'journalctl | grep sshd | grep "Disconnected from"' | less
```

Why the additional quoting ?

Well, our logs may be quite large, and it’s wasteful to stream it all to our computer and then do the filtering

Instead, we can do the filtering on the remote server, and then massage the data locally

`less` gives us a “pager” that allows us to scroll up and down through the long output

To save some additional traffic while we debug our command-line, we can even stick the current filtered logs into a file so that we don’t have to access the network while developing:

```bash
ssh myserver 'journalctl | grep sshd | grep "Disconnected from"' > ssh.log
less ssh.log
```

There’s still a lot of noise here

There are a lot of ways to get rid of that, but let’s look at one of the most powerful tools in your toolkit: `sed`

---

`sed` is a “stream editor” that builds on top of the old `ed` editor

In it, you basically give short commands for how to modify the file, rather than manipulate its contents directly (although you can do that too)

There are tons of commands, but one of the most common ones is `s`: substitution

For example, we can write:

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed 's/.*Disconnected from //'
```

What we just wrote was a simple regular expression; a powerful construct that lets you match text against patterns

The `s` command is written on the form: `s/REGEX/SUBSTITUTION/`, where `REGEX` is the regular expression you want to search for, and `SUBSTITUTION` is the text you want to substitute matching text with.

(You may recognize this syntax from the “Search and replace” section of our Vim lecture notes! Indeed, Vim uses a syntax for searching and replacing that is similar to sed’s substitution command. Learning one tool often helps you become more proficient with others.)

---

Regular expressions

Regular expressions 是一种特别有用且通用的技能，因此花一些时间来理解它的运作方式是十分值得的

Let’s start by looking at the one we used above: `/.*Disconnected from /`

Regular expressions are usually (though not always) surrounded by `/`

Most ASCII characters just carry their normal meaning, but some characters have “special” matching behavior

> Exactly which characters do what vary somewhat between different implementations of regular expressions, which is a source of great frustration.

下面给出了一些常见的 pattern

- `.` means “any single character” except newline
- `*` zero or more of the preceding match
- `+` one or more of the preceding match
- `[abc]` any one character of a, b, and c
- `(RX1|RX2)` either something that matches RX1 or RX2
- `^` the start of the line
- `$` the end of the line

---

`sed` 的正则表达式有点奇怪，你如果不给 `sed` 加一个 `-E` 参数，你就必须在很多字符的前面加一个 `\` 来让这些字符拥有 “special” matching behavior

So, looking back at `/.*Disconnected from /`, we see that it matches any text that starts with any number of characters, followed by the literal string “Disconnected from ”. Which is what we wanted.

> But beware, regular expressions are trixy

What if someone tried to log in with the username “Disconnected from”? We’d have:

```log
Jan 17 03:13:00 thesquareplanet.com sshd[2631]: Disconnected from invalid user Disconnected from 46.97.239.16 port 55920 [preauth]
```

What would we end up with? Well, `*` and `+` are, by default, “greedy”. They will match as much text as they can

> when you use `.*` and any of these sort of range expressions indirect expressions, they are greedy !

So, in the above, we’d end up with just

```log
46.97.239.16 port 55920 [preauth]
```

Which may not be what we wanted

In some regular expression implementations, you can just suffix `*` or `+` with a `?` to make them non-greedy, but sadly `sed` doesn’t support that

We could switch to perl’s command-line mode though, which does support that construct:

```perl
perl -pe 's/.*?Disconnected from //'
```

We’ll stick to `sed` for the rest of this, because it’s by far the more common tool for these kinds of jobs

`sed` can also do other handy things like

- print lines following a given match
- do multiple substitutions per invocation
- search for things
- ...

But we won’t cover that too much here

`sed` is basically an entire topic in and of itself, but there are often better tools

---

Okay, so we also have a suffix we’d like to get rid of, How might we do that ?

It’s a little tricky to match just the text that follows the username, especially if the username can have spaces and such

What we need to do is match the whole line:

```bash
| sed -E 's/^.*Disconnected from (invalid |authenticating )?user .* [^ ]+ port [0-9]+( \[preauth\])?$//'
```

Let’s look at what’s going on with a [regex debugger](https://regex101.com/r/qqbZqh/2). Okay, so the start is still as before. Then, we’re matching any of the “user” variants (there are two prefixes in the logs). Then we’re matching on any string of characters where the username is. Then we’re matching on any single word (`[^ ]+`; any non-empty sequence of non-space characters). Then the word “port” followed by a sequence of digits. Then possibly the suffix `[preauth]`, and then the end of the line.

> Notice that with this technique, as username of “Disconnected from” won’t confuse us any more. Can you see why?

---

`^` at the beginning and `$` at the end are very important,

because imagine that someone made their username the entire log string, then now if you try to match this pattern, it would match the username itself, which is not what we want.

generally you will want to try to anchor your patterns wherever you can to avoid those kind of oddities.

---

There is one problem with this though, and that is that the entire log becomes empty. We want to keep the username after all

For this, we can use “capture groups”

Any text matched by a regex surrounded by parentheses is stored in a numbered capture group

These are available in the substitution (and in some engines, even in the pattern itself!)

as `\1, \2, \3`, etc

So:

```bash
| sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
```

As you can probably imagine, you can come up with really complicated regular expressions.

For example, here’s an article on how you might match an [e-mail address](https://www.regular-expressions.info/email.html). It’s [not easy](https://emailregex.com/). And there’s [lots of discussion](https://stackoverflow.com/questions/201323/how-to-validate-an-email-address-using-a-regular-expression/1917982). And people have [written tests](https://fightingforalostcause.net/content/misc/2006/compare-email-regex.php). And [test matrices](https://mathiasbynens.be/demo/url-regex).You can even write a regex for determining if a given number [is a prime number](https://www.noulakaz.net/2007/03/18/a-regular-expression-to-check-for-prime-numbers/).

Regular expressions are notoriously hard to get right, but they are also very handy to have in your toolbox!

---

Back to data wrangling:

Okay, so we now have

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
```

`sed` can do all sorts of other interesting things, like injecting text (with the `i` command), explicitly printing lines (with the `p` command), selecting lines by index, and lots of other things. Check `man sed`!

Anyway. What we have now gives us a list of all the usernames that have attempted to log in. But this is pretty unhelpful

我们接下来将出现次数多的用户揪出来 ！

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
 | sort | uniq -c
```

`sort` will, well, sort its input. `uniq -c` will collapse consecutive lines that are the same into a single line, prefixed with a count of the number of occurrences.

We probably want to sort that too and only keep the most common usernames:

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
 | sort | uniq -c
 | sort -nk1,1 | tail -n10
```

`sort -n` will sort in numeric (instead of lexicographic) order. `-k1,1` means “sort by only the first whitespace-separated column”

The `,n` part says “sort until the `n`th field, where the default is the end of the line

In this particular example, sorting by the whole line wouldn’t matter, but we’re here to learn !

If we wanted the least common ones, we could use `head` instead of `tail`. There’s also `sort -r`, which sorts in reverse order.

---

Okay, so that’s pretty cool, but what if we’d like these extract only the usernames as a comma-separated list instead of one per line, perhaps for a config file?

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
 | sort | uniq -c
 | sort -nk1,1 | tail -n10
 | awk '{print $2}' | paste -sd,
```

If you’re using macOS: note that the command as shown won’t work with the BSD `paste` shipped with macOS. See exercise 4 from the shell tools lecture for more on the difference between BSD and GNU coreutils and instructions for how to install GNU coreutils on macOS.

Let’s start with `paste`: it lets you combine lines (`-s`) by a given single-character delimiter (`-d`; `,` in this case). But what’s this `awk` business?

---

awk – another editor, a column based stream processor

`awk` is a programming language that just happens to be really good at processing text streams

There is a lot to say about awk if you were to learn it properly, but as with many other things here, we’ll just go through the basics.

---

First, what does `{print $2}` do ?

Well, `awk` programs take the form of an optional pattern plus a block saying what to do if the pattern matches a given line.

The default pattern (which we used above) matches all lines.

Inside the block, `$0` is set to the entire line’s contents, and `$1` through `$n` are set to the `n`th field of that line, when separated by the `awk` field separator (whitespace by default, change with `-F`).

In this case, we’re saying that, for every line, print the contents of the second field, which happens to be the username!

---

Let’s see if we can do something fancier.

Let’s compute the number of single-use usernames that start with `c` and end with `e`

```bash
| awk '$1 == 1 && $2 ~ /^c[^ ]*e$/ { print $2 }' | wc -l
```

There’s a lot to unpack here

First, notice that we now have a pattern (the stuff that goes before `{...}`).

The pattern says that the first field of the line should be equal to 1 (that’s the count from `uniq -c`), and that the second field should match the given regular expression.

And the block just says to print the username.

We then count the number of lines in the output with `wc -l`.

> However, `awk` is a programming language, remember ?

```awk
BEGIN { rows = 0 }
$1 == 1 && $2 ~ /^c[^ ]*e$/ { rows += $1 }
END { print rows }
```

`BEGIN` is a pattern that matches the start of the input (and `END` matches the end).

Now, the per-line block just adds the count from the first field (although it’ll always be 1 in this case), and then we print it out at the end.

---

In fact, we could get rid of `grep` and `sed` entirely, because `awk` [can do it all](https://backreference.org/2010/02/10/idiomatic-awk/), but we’ll leave that as an exercise to the reader.

---

Analyzing data

You can do math directly in your shell using `bc`, a calculator that can read from STDIN!

For example, add the numbers on each line together by concatenating them together, delimited by `+`

```bash
| paste -sd+ | bc -l
```

Or produce more elaborate expressions

```bash
echo "2*($(data | paste -sd+))" | bc -l
```

You can get stats in a variety of ways. [st](https://github.com/nferraz/st) is pretty neat, but if you already have [R](https://www.r-project.org/):

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
 | sort | uniq -c
 | awk '{print $1}' | R --no-echo -e 'x <- scan(file="stdin", quiet=TRUE); summary(x)'
```

R is another (weird) programming language that’s great at data analysis and [plotting](https://ggplot2.tidyverse.org/).

We won’t go into too much detail, but suffice to say that summary prints summary statistics for a vector, and we created a vector containing the input stream of numbers, so R gives us the statistics we wanted!

If you just want some simple plotting, `gnuplot` is your friend:

```bash
ssh myserver journalctl
 | grep sshd
 | grep "Disconnected from"
 | sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \[preauth\])?$/\2/'
 | sort | uniq -c
 | sort -nk1,1 | tail -n10
 | gnuplot -p -e 'set boxwidth 0.5; plot "-" using 1:xtic(2) with boxes'
```

---

Data wrangling to make arguments

Sometimes you want to do data wrangling to find things to install or remove based on some longer list.

The data wrangling we’ve talked about so far + `xargs` can be a powerful combo.

For example, as seen in lecture, I can use the following command to uninstall old nightly builds of Rust from my system by extracting the old build names using data wrangling tools and then passing them via `xargs` to the uninstaller

```bash
rustup toolchain list | grep nightly | grep -vE "nightly-x86" | sed 's/-x86.*//' | xargs rustup toolchain uninstall
```

---

Wrangling binary data

So far, we have mostly talked about wrangling textual data, but pipes are just as useful for binary data.

For example, we can use ffmpeg to capture an image from our camera, convert it to grayscale, compress it, send it to a remote machine over SSH, decompress it there, make a copy, and then display it.

```bash
ffmpeg -loglevel panic -i /dev/video0 -frames 1 -f image2 -
 | convert - -colorspace gray -
 | gzip
 | ssh mymachine 'gzip -d | tee copy.jpg | env DISPLAY=:0 feh -'
```

### Notes on the class

`grep` is buffering..., see [here](https://askubuntu.com/questions/562344/what-does-grep-line-buffering-do)

---

```bash
echo 'aba' | sed 's/[ab]//'
```

above command will print `ba` to the STDOUT

because what regular expressions will do especially in the default mode is they will just match the pattern once and then apply the replacement once per line. that is what's said normally does.

you can provide the `g` modifier which says do this as many times as it keeps matching, which in this case would erase the entire line because every single character is either an **a** or **b**.

```bash
echo 'aba' | sed 's/[ab]//g'
```

print nothing.

---

because `sed` is a really old tool and so it support only a very old version of very "cool" expressions, generally you will want to run it with `-E` which makes it use a more modern syntax that supports more things.

if you are in a place where you can't, you have to prefix these with `\` to say I want the special meaning of parenthesis otherwise they were just match a literal parenthesis, which is probably not what you want.

```bash
echo 'abcaba' | sed 's/\(ab\)*//g'

# equals to

echo 'abcaba' | sed -E 's/(ab)*//g'
```

for get ride of `-E`, I just set `alias sed="sed -E"`～

---

regular expressions by default only match perline, they will not match across new lines.

### Exericses after this class

1、Take this [short interactive regex tutorial](https://regexone.com/).

done.

2、

Find the number of words (in `/usr/share/dict/words`) that contain at least three `a`s and don’t have a `'s` ending.

What are the three most common last two letters of those words?

`sed`’s `y` command, or the `tr` program, may help you with case insensitivity.

How many of those two-letter combinations are there?

![20220729121206](https://aliyun-oss-lpj.oss-cn-qingdao.aliyuncs.com/images/by-clipboard/20220729121206.png)

for a challenge: which combinations do not occur?

```bash
# all.sh
#!/usr/bin/env bash

for i in {a..z}; do
    for j in {a..z}; do
        echo "$i$j"
    done
done
```

![20220729155533](https://aliyun-oss-lpj.oss-cn-qingdao.aliyuncs.com/images/by-clipboard/20220729155533.png)

3、

妄想直接执行命令 `sed s/REGEX/SUBSTITUTION/ input.txt > input.txt` 做原地替换其实 is a bad idea,

why?

![20220729223954](https://aliyun-oss-lpj.oss-cn-qingdao.aliyuncs.com/images/by-clipboard/20220729223954.png)

瞅见没 ？！原文件还没来得及被处理就先被清空了 ！

Is this particular to `sed`? Use `man sed` to find out how to accomplish this.

![20220729161807](https://aliyun-oss-lpj.oss-cn-qingdao.aliyuncs.com/images/by-clipboard/20220729161807.png)

4、

Find your average, median, and max system boot time over the last ten boots. Use `journalctl` on Linux and `log show` on macOS, and look for log timestamps near the beginning and end of each boot. On Linux, they may look something like: 

```log
Logs begin at ...
```

and

```log
systemd[577]: Startup finished in ...
```

On macOS, [look for](https://eclecticlight.co/2018/03/21/macos-unified-log-3-finding-your-way/):

```log
=== system boot:
```

and

```log
Previous shutdown cause: 5
```

![20220729172614](https://aliyun-oss-lpj.oss-cn-qingdao.aliyuncs.com/images/by-clipboard/20220729172614.png)

5、（TODO ！！！）

Look for boot messages that are not shared between your past three reboots (see `journalctl`’s `-b` flag).

Break this task down into multiple steps.

First, find a way to get just the logs from the past three boots.

There may be an applicable flag on the tool you use to extract the boot logs, or you can use `sed '0,/STRING/d'` to remove all lines previous to one that matches `STRING`.

Next, remove any parts of the line that always varies (like the timestamp).

Then, de-duplicate the input lines and keep a count of each one (`uniq` is your friend).

And finally, eliminate any line whose count is 3 (since it was shared among all the boots).

6、（TODO ！！！）

Find an online data set like [this one](https://stats.wikimedia.org/EN/TablesWikipediaZZ.htm), [this one](https://stats.wikimedia.org/EN/TablesWikipediaZZ.htm), or maybe one [from here](https://www.springboard.com/blog/free-public-data-sets-data-science-project/).

Fetch it using `curl` and extract out just two columns of numerical data.

If you’re fetching HTML data, [pup](https://github.com/EricChiang/pup) might be helpful.

For JSON data, try [jq](https://stedolan.github.io/jq/).

Find the min and max of one column in a single command, and the difference of the sum of each column in another.

